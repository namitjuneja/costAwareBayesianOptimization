{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import botorch\n",
    "import gpytorch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_default_dtype(torch.float64) # avoid matrix not positive semi-definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: init points\n",
    "train_x, train_y, best_y = get_initial_data(10, ack, show_plot=False)\n",
    "\n",
    "# Step 2; init gp model and fit\n",
    "single_model, mll = init_gp_model(train_x, train_y)\n",
    "\n",
    "# Step 3: Init acq func\n",
    "ei = init_acq_func(single_model, best_y)\n",
    "\n",
    "# Step 4: Generate candidates\n",
    "candidates = gen_candidates(1, ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  1 | Best: 2.774470419096808 | ( 23.07,  -4.72) => 8.43\n",
      "#  2 | Best: 2.774470419096808 | ( 23.26,  27.80) => 7.87\n",
      "#  3 | Best: 2.774470419096808 | (-32.00,  32.00) => 9.87\n",
      "#  4 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#  5 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#  6 | Best: 2.774470419096808 | ( 32.00, -32.00) => 10.81\n",
      "#  7 | Best: 2.774470419096808 | ( 32.00, -18.87) => 10.81\n",
      "#  8 | Best: 2.774470419096808 | ( 31.14,  32.00) => 9.19\n",
      "#  9 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.38\n",
      "# 10 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 11 | Best: 2.774470419096808 | ( 30.36, -32.00) => 10.81\n",
      "# 12 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.10\n",
      "# 13 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 14 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 15 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 16 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 17 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 18 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 19 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 20 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 21 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 22 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 23 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 24 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 25 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 26 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 27 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 28 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 29 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 30 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 31 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 32 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 33 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 34 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 35 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 36 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 37 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 38 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 39 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 40 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 41 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 42 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 43 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 44 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 45 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 46 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 47 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 48 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 49 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 50 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 51 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 52 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 53 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 54 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 55 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 56 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 57 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 58 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 59 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 60 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 61 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 62 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 63 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 64 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 65 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 66 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 67 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 68 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 69 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 70 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 71 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 72 | Best: 2.774470419096808 | ( 31.66, -22.30) => 10.81\n",
      "# 73 | Best: 2.774470419096808 | (-31.89,  32.00) => 9.78\n",
      "# 74 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.75\n",
      "# 75 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 76 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 77 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 78 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 79 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 80 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 81 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 82 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 83 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 84 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 85 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 86 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 87 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 88 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 89 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 90 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 91 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 92 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "# 93 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 94 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 95 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 96 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "# 97 | Best: 2.774470419096808 | (  9.85, -21.27) => 10.81\n",
      "# 98 | Best: 2.774470419096808 | (-32.00,  32.00) => 6.03\n",
      "# 99 | Best: 2.774470419096808 | (-17.26, -24.81) => 10.81\n",
      "#100 | Best: 2.774470419096808 | (-32.00,  32.00) => 9.11\n",
      "#101 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#102 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#103 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#104 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#105 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#106 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#107 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#108 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#109 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#110 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#111 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#112 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#113 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#114 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#115 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#116 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#117 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#118 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#119 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#120 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#121 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#122 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#123 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#124 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#125 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#126 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#127 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#128 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#129 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#130 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#131 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#132 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#133 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#134 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#135 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#136 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#137 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#138 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#139 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#140 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#141 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#142 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#143 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#144 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#145 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#146 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#147 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#148 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#149 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#150 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#151 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#152 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#153 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#154 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#155 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#156 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#157 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#158 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#159 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#160 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#161 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#162 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#163 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#164 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#165 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#166 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#167 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#168 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#169 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#170 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#171 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#172 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#173 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#174 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#175 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#176 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#177 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#178 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#179 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#180 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#181 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#182 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#183 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#184 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#185 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#186 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#187 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#188 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#189 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#190 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#191 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#192 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#193 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#194 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/namit/.local/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-03 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#195 | Best: 2.774470419096808 | ( -0.31, -15.57) => 10.81\n",
      "#196 | Best: 2.774470419096808 | ( 32.00,  30.80) => 5.65\n",
      "#197 | Best: 2.774470419096808 | ( 32.00, -31.17) => 10.24\n",
      "#198 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.39\n",
      "#199 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#200 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#201 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#202 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#203 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#204 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#205 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#206 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#207 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#208 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#209 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#210 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#211 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#212 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#213 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#214 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#215 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#216 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#217 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#218 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#219 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#220 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#221 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#222 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#223 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#224 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#225 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#226 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#227 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#228 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#229 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#230 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#231 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#232 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#233 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#234 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#235 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#236 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#237 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#238 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#239 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#240 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#241 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#242 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#243 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#244 | Best: 2.774470419096808 | ( 32.00, -32.00) => 10.81\n",
      "#245 | Best: 2.774470419096808 | (-32.00,  32.00) => 10.81\n",
      "#246 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#247 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#248 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n",
      "#249 | Best: 2.774470419096808 | ( 32.00,  32.00) => 10.81\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    # Step 1: Evaluate candidates\n",
    "    evaluation = evaluate_candidates(candidates, ack)\n",
    "    train_x = torch.cat([train_x, candidates])\n",
    "    train_y = torch.cat([train_y, evaluation])\n",
    "    best_y = train_y.min()\n",
    "    \n",
    "    # Step 2: Init Gp Model\n",
    "    single_model, mll = init_gp_model(train_x, train_y)\n",
    "    \n",
    "    # Step 3: Init acq func\n",
    "    ei = init_acq_func(single_model, best_y)\n",
    "    \n",
    "    # Step 4: Acquire new candidate\n",
    "    candidates = gen_candidates(1, ei)\n",
    "\n",
    "    print(f\"#{i+1:3,} | Best: {best_y} | ({from_unit_cube(candidates[0,0]):6,.02f}, {from_unit_cube(candidates[0,1]):6,.02f}) => {evaluation[0,0]:,.02f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(range(train_y.shape[0]), train_y[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,10)\n",
    "y = np.linspace(0,1,10)\n",
    "x_mesh, y_mesh = np.meshgrid(x,y)\n",
    "x_mesh_denormalized = from_unit_cube(x_mesh)\n",
    "y_mesh_denormalized = from_unit_cube(y_mesh)\n",
    "\n",
    "\n",
    "mean_train_x = single_model.posterior(train_x).mean.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter3D(train_x[:,0], train_x[:,1], mean_train_x.squeeze(), color=\"yellow\")\n",
    "ax.scatter3D(train_x[:,0], train_x[:,1], train_y.squeeze())\n",
    "\n",
    "\n",
    "x = np.linspace(0,1,64)\n",
    "y = np.linspace(0,1,64)\n",
    "x_mesh, y_mesh = np.meshgrid(x,y)\n",
    "mean_compatibale_coordinates = torch.tensor(  np.stack((x_mesh, y_mesh), axis=-1).reshape((4096,2))  )\n",
    "mean = single_model.posterior(mean_compatibale_coordinates).mean.detach().numpy()\n",
    "\n",
    "mean_mesh = mean.reshape((64,64))\n",
    "ax.plot_surface(x_mesh, y_mesh, mean_mesh)\n",
    "\n",
    "\n",
    "ax.plot_surface(x_mesh, y_mesh, ack(from_unit_cube(x_mesh), from_unit_cube(y_mesh)), color=\"yellow\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# posterior surface plot\n",
    "ax.plot_surface(x_mesh_denormalized, y_mesh_denormalized, mean)\n",
    "ax.scatter(0,0,0, color=\"yellow\")\n",
    "\n",
    "# original function plot\n",
    "x = np.linspace(-32,32,64)\n",
    "y = np.linspace(-32,32,64)\n",
    "x_ids, y_ids = np.meshgrid(x,y)\n",
    "result = ack(x_ids,y_ids)\n",
    "ax.plot_surface(x_ids, y_ids, result, color=\"yellow\", alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
